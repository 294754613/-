{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import random\n",
    "import scipy.ndimage\n",
    "try:\n",
    "    from tqdm import tqdm  # long waits are not fun\n",
    "except:\n",
    "    print('TQDM does make much nicer wait bars...')\n",
    "    tqdm = lambda x: x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = \"train_subset*/\"\n",
    "# subset = \"subset*/\"###while need to preprocess luna ,chose this\n",
    "# subset = \"val_subset*/\"\n",
    "\n",
    "tianchi_path = \"./tianchi\"\n",
    "# tianchi_path = \"./LUNA 2016\"###while need to preprocess luna16 ,chose this\n",
    "\n",
    "output_path = \"./tianchi/tianchi-2D/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = os.path.join(output_path, \"traindata/\")#subset)\n",
    "\n",
    "print(\"train_data_path: %s\" % train_data_path)\n",
    "train_images = glob(train_data_path + \"*.npy\")\n",
    "print(train_images)\n",
    "\n",
    "tmp_workspace = os.path.join(output_path, \"64/\")###the width we need to cut,it can also be 48,80,96,112...\n",
    "\n",
    "if not os.path.exists(tmp_workspace):\n",
    "    os.makedirs(tmp_workspace)\n",
    "\n",
    "mask_workspace = os.path.join(output_path, \"trainlabel/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Helper function to get rows in data frame associated\n",
    "# with each file\n",
    "def get_filename(file_list, case):\n",
    "    for f in file_list:\n",
    "        if case in f:\n",
    "            return (f)\n",
    "\n",
    "\n",
    "#\n",
    "# The locations of the nodes\n",
    "df_node = pd.read_csv(tianchi_path + \"/csv/train/annotations.csv\")\n",
    "# df_node = pd.read_csv(tianchi_path + \"/CSVFILES/annotations.csv\")###while need to preprocess luna ,chose this\n",
    "# df_node = pd.read_csv(tianchi_path + \"/csv/val/annotations.csv\")\n",
    "df_node[\"file\"] = df_node[\"seriesuid\"].map(lambda file_name: get_filename(train_images, file_name))\n",
    "df_node = df_node.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fcount, img_file in enumerate(tqdm(train_images)):\n",
    "    mini_df = df_node[df_node[\"file\"] == img_file]  # get all nodules associate with file\n",
    "    if mini_df.shape[0] > 0:  # some files may not have a nodule--skipping those\n",
    "        img_array = np.load(img_file)\n",
    "        masks=np.load(img_file.replace('data','label'))\n",
    "        height, width, num_z =img_array.shape \n",
    "        oy,ox,oz=list(map(float,img_file.split('_')[-4:-1] ))\n",
    "        h=7\n",
    "        h1=h//2\n",
    "        r=32 #it is the half of width we need to cut,it can also be 24,40,48,56...\n",
    "        for node_idx, cur_row in mini_df.iterrows():\n",
    "            node_x = round(min(max(2*r-2,cur_row[\"coordX\"]-ox),width-2*r+2))\n",
    "            node_y = round(min(max(2*r-2,cur_row[\"coordY\"]-oy),height-2*r+2))\n",
    "            node_z = cur_row[\"coordZ\"]-oz\n",
    "            diam = cur_row[\"diameter_mm\"]\n",
    "            quater=diam/4\n",
    "            value=np.arange(max(h1,round(node_z-h1-quater)),min(round(node_z+h1+1+quater),num_z-h1))\n",
    "            middle=np.random.randint(2-r,r-2,size=[len(value),2])+[node_y,node_x]\n",
    "            for num,post in enumerate(middle):\n",
    "                img=img_array[post[0]-r:post[0]+r,post[1]-r:post[1]+r,value[num]-h1:value[num]+h1+1]\n",
    "                mask=masks[post[0]-r:post[0]+r,post[1]-r:post[1]+r,value[num]-h1:value[num]+h1+1,:]\n",
    "                np.save(tmp_workspace+'image_%s_%s_%s_%s.npy'%(cur_row[\"seriesuid\"],post[0],post[1],value[num]),img)\n",
    "                np.save(tmp_workspace+'mask_%s_%s_%s_%s.npy'%(cur_row[\"seriesuid\"],post[0],post[1],value[num]),mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
